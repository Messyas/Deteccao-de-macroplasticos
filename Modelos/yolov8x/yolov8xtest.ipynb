{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba25acdb-b8ef-4155-b317-a7a9ccd4bd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ocorreu um erro: [Errno 2] No such file or directory: '/home/messyas/ml/jetson/runs/detect/yolov8xtrain/weights/best.pt'\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model_path = '/home/messyas/ml/jetson/runs/detect/yolov8xtrain/weights/best.pt'\n",
    "data_yaml_path = '/home/messyas/ml/data/tccdata/yolo_dataset/data.yaml'\n",
    "\n",
    "try:\n",
    "    model = YOLO(model_path)\n",
    "    results = model.val(data=data_yaml_path, split='test', save_json=False)\n",
    "    map_50_95 = results.box.map\n",
    "    map_50 = results.box.map50\n",
    "    try:\n",
    "        recall = results.results_dict['metrics/recall(B)']\n",
    "    except KeyError:\n",
    "        print(\"A chave 'metrics/recall(B)' não foi encontrada. Verifique as chaves disponíveis:\")\n",
    "        print(results.results_dict.keys())\n",
    "        recall = None \n",
    "\n",
    "    f1_score = None\n",
    "    if recall is not None:\n",
    "        try:\n",
    "            precision = results.results_dict['metrics/precision(B)']\n",
    "            if (precision + recall) > 0:\n",
    "                f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "            else:\n",
    "                f1_score = 0\n",
    "        except KeyError:\n",
    "            precision = None\n",
    "\n",
    "    print(\"\\n--- Métricas YOLOv8x ---\")\n",
    "    print(f\"mAP (50:95): {map_50_95:.4f} ({map_50_95 * 100:.2f} %)\")\n",
    "    print(f\"mAP50:       {map_50:.4f} ({map_50 * 100:.2f} %)\")\n",
    "\n",
    "    if recall is not None:\n",
    "        print(f\"Revocação:   {recall:.4f} ({recall * 100:.2f} %)\")\n",
    "    else:\n",
    "        print(\"Revocação:   N/A\")\n",
    "\n",
    "    if f1_score is not None:\n",
    "        print(f\"F1-Score:    {f1_score:.4f} ({f1_score * 100:.2f} %)\")\n",
    "    else:\n",
    "        print(\"F1-Score:    N/A\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Ocorreu um erro: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed43dafd-030e-4771-bbd5-f56898acf497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando modelo de: /home/messyas/ml/jetson/runs/detect/yolov8xtrain/weights/best.pt\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/messyas/ml/jetson/runs/detect/yolov8xtrain/weights/best.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 21\u001b[39m\n\u001b[32m     19\u001b[39m os.makedirs(OUTPUT_DIR, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCarregando modelo de: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m model = \u001b[43mYOLO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m class_names = model.names\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModelo carregado. Classes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/detectron/lib/python3.11/site-packages/ultralytics/models/yolo/model.py:53\u001b[39m, in \u001b[36mYOLO.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m     50\u001b[39m     \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m = new_instance.\u001b[34m__dict__\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m     \u001b[38;5;66;03m# Continue with default YOLO initialization\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/detectron/lib/python3.11/site-packages/ultralytics/engine/model.py:148\u001b[39m, in \u001b[36mModel.__init__\u001b[39m\u001b[34m(self, model, task, verbose)\u001b[39m\n\u001b[32m    146\u001b[39m     \u001b[38;5;28mself\u001b[39m._new(model, task=task, verbose=verbose)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m# Delete super().training for accessing self.model.training\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/detectron/lib/python3.11/site-packages/ultralytics/engine/model.py:292\u001b[39m, in \u001b[36mModel._load\u001b[39m\u001b[34m(self, weights, task)\u001b[39m\n\u001b[32m    289\u001b[39m weights = checks.check_model_file_from_stem(weights)  \u001b[38;5;66;03m# add suffix, i.e. yolo11n -> yolo11n.pt\u001b[39;00m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(weights).rpartition(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     \u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.ckpt = \u001b[43mattempt_load_one_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    293\u001b[39m     \u001b[38;5;28mself\u001b[39m.task = \u001b[38;5;28mself\u001b[39m.model.args[\u001b[33m\"\u001b[39m\u001b[33mtask\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mself\u001b[39m.overrides = \u001b[38;5;28mself\u001b[39m.model.args = \u001b[38;5;28mself\u001b[39m._reset_ckpt_args(\u001b[38;5;28mself\u001b[39m.model.args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/detectron/lib/python3.11/site-packages/ultralytics/nn/tasks.py:1334\u001b[39m, in \u001b[36mattempt_load_one_weight\u001b[39m\u001b[34m(weight, device, inplace, fuse)\u001b[39m\n\u001b[32m   1321\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mattempt_load_one_weight\u001b[39m(weight, device=\u001b[38;5;28;01mNone\u001b[39;00m, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m, fuse=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   1322\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1323\u001b[39m \u001b[33;03m    Load a single model weights.\u001b[39;00m\n\u001b[32m   1324\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1332\u001b[39m \u001b[33;03m        (tuple): Tuple containing the model and checkpoint.\u001b[39;00m\n\u001b[32m   1333\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1334\u001b[39m     ckpt, weight = \u001b[43mtorch_safe_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load ckpt\u001b[39;00m\n\u001b[32m   1335\u001b[39m     args = {**DEFAULT_CFG_DICT, **(ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mtrain_args\u001b[39m\u001b[33m\"\u001b[39m, {}))}  \u001b[38;5;66;03m# combine model and default args, preferring model args\u001b[39;00m\n\u001b[32m   1336\u001b[39m     model = (ckpt.get(\u001b[33m\"\u001b[39m\u001b[33mema\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ckpt[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m]).to(device).float()  \u001b[38;5;66;03m# FP32 model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/detectron/lib/python3.11/site-packages/ultralytics/nn/tasks.py:1239\u001b[39m, in \u001b[36mtorch_safe_load\u001b[39m\u001b[34m(weight, safe_only)\u001b[39m\n\u001b[32m   1237\u001b[39m                 ckpt = torch.load(f, pickle_module=safe_pickle)\n\u001b[32m   1238\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m             ckpt = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcpu\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# e.name is missing module name\u001b[39;00m\n\u001b[32m   1242\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.name == \u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/detectron/lib/python3.11/site-packages/ultralytics/utils/patches.py:116\u001b[39m, in \u001b[36mtorch_load\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TORCH_1_13 \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mweights_only\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m    114\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mweights_only\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_torch_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/detectron/lib/python3.11/site-packages/torch/serialization.py:1479\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args.keys():\n\u001b[32m   1477\u001b[39m     pickle_load_args[\u001b[33m\"\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1479\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[32m   1480\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[32m   1481\u001b[39m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[32m   1482\u001b[39m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[32m   1483\u001b[39m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[32m   1484\u001b[39m         orig_position = opened_file.tell()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/detectron/lib/python3.11/site-packages/torch/serialization.py:759\u001b[39m, in \u001b[36m_open_file_like\u001b[39m\u001b[34m(name_or_buffer, mode)\u001b[39m\n\u001b[32m    757\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_open_file_like\u001b[39m(name_or_buffer: FileLike, mode: \u001b[38;5;28mstr\u001b[39m) -> _opener[IO[\u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    761\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/detectron/lib/python3.11/site-packages/torch/serialization.py:740\u001b[39m, in \u001b[36m_open_file.__init__\u001b[39m\u001b[34m(self, name, mode)\u001b[39m\n\u001b[32m    739\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike[\u001b[38;5;28mstr\u001b[39m]], mode: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/home/messyas/ml/jetson/runs/detect/yolov8xtrain/weights/best.pt'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "import random\n",
    "from ultralytics import YOLO\n",
    "import numpy as np \n",
    "\n",
    "MODEL_PATH = '/home/messyas/ml/jetson/runs/detect/yolov8xtrain/weights/best.pt'\n",
    "TEST_IMG_DIR = '/home/messyas/ml/data/tccdata/yolo_dataset/images/test/'\n",
    "DATA_YAML_PATH = '/home/messyas/ml/data/tccdata/yolo_dataset/data.yaml'\n",
    "\n",
    "OUTPUT_DIR = './output_visualizations_gray/' \n",
    "NUM_IMAGES_TO_SAVE = 16\n",
    "CONF_THRESHOLD = 0.5  \n",
    "BOX_THICKNESS = 4\n",
    "FONT_SCALE = 0.5\n",
    "FONT_THICKNESS = 1\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Carregando modelo de: {MODEL_PATH}\")\n",
    "model = YOLO(MODEL_PATH)\n",
    "class_names = model.names\n",
    "print(f\"Modelo carregado. Classes: {class_names}\")\n",
    "\n",
    "np.random.seed(42) \n",
    "colors = np.random.randint(50, 256, size=(len(class_names), 3), dtype='uint8').tolist()\n",
    "\n",
    "try:\n",
    "    all_test_images = [os.path.join(TEST_IMG_DIR, f) for f in os.listdir(TEST_IMG_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    if not all_test_images:\n",
    "        print(f\"ERRO: Nenhuma imagem encontrada em: {TEST_IMG_DIR}\")\n",
    "        exit()\n",
    "    if len(all_test_images) < NUM_IMAGES_TO_SAVE:\n",
    "        print(f\"Aviso: Encontradas apenas {len(all_test_images)} imagens, processando todas.\")\n",
    "        selected_images = all_test_images\n",
    "    else:\n",
    "        selected_images = random.sample(all_test_images, NUM_IMAGES_TO_SAVE)\n",
    "    print(f\"\\nSelecionadas {len(selected_images)} imagens para visualização.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: Diretório de imagens de teste não encontrado: {TEST_IMG_DIR}\")\n",
    "    exit()\n",
    "\n",
    "for img_path in selected_images:\n",
    "    print(f\"Processando: {os.path.basename(img_path)}...\")\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    results = model.predict(source=img_path, conf=CONF_THRESHOLD, verbose=False)\n",
    "    result = results[0] \n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_out = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "    boxes = result.boxes.xyxy.cpu().numpy()\n",
    "    scores = result.boxes.conf.cpu().numpy()\n",
    "    classes = result.boxes.cls.cpu().numpy()\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        x1, y1, x2, y2 = map(int, boxes[i])\n",
    "        score = scores[i]\n",
    "        cls_id = int(classes[i])\n",
    "        cls_name = class_names[cls_id]\n",
    "        color = colors[cls_id]\n",
    "\n",
    "\n",
    "        cv2.rectangle(img_out, (x1, y1), (x2, y2), color, BOX_THICKNESS)\n",
    "\n",
    "      \n",
    "        label = f\"{cls_name}: {score:.2f}\"\n",
    "        (w, h), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, FONT_THICKNESS)\n",
    "       \n",
    "        text_y = y1 - 5 if y1 - 5 > h else y1 + h + 5 \n",
    "        cv2.rectangle(img_out, (x1, text_y - h), (x1 + w, text_y), color, -1) \n",
    "        cv2.putText(img_out, label, (x1, text_y), cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, (0, 0, 0), FONT_THICKNESS) \n",
    "\n",
    "\n",
    "    base_name = os.path.basename(img_path)\n",
    "    save_path = os.path.join(OUTPUT_DIR, f\"gray_pred_{base_name}\")\n",
    "    cv2.imwrite(save_path, img_out)\n",
    "    print(f\" imagem salva em: {save_path}\")\n",
    "\n",
    "print(f\"\\n imagens salvas em '{OUTPUT_DIR}'.\")\n",
    "\n",
    "try:\n",
    "    val_results = model.val(data=DATA_YAML_PATH, split='test', verbose=False)\n",
    "    print(f\"mAP50-95: {val_results.box.map:.4f}\")\n",
    "    print(f\"mAP50:    {val_results.box.map50:.4f}\")\n",
    "    print(f\"mAP75:    {val_results.box.map75:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"ERRO ao executar a validação: {e}\")\n",
    "    print(f\"Verifique o caminho do arquivo YAML: {DATA_YAML_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b07aaf0-94a9-48b3-9b2e-dac72dd80b3f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FINAL_THRESHOLD_JUPYTER' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 115\u001b[39m\n\u001b[32m    111\u001b[39m     draw_enhanced_boxes(img_rgb, img_path, image_predictions_for_plot, yolo_names, output_dir)\n\u001b[32m    113\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mProcesso concluído.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m \u001b[43mrun_prediction_for_jupyter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 69\u001b[39m, in \u001b[36mrun_prediction_for_jupyter\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     67\u001b[39m img_path = IMAGE_TO_PROCESS\n\u001b[32m     68\u001b[39m output_dir = OUTPUT_DIR_JUPYTER\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m final_score_threshold = \u001b[43mFINAL_THRESHOLD_JUPYTER\u001b[49m\n\u001b[32m     71\u001b[39m os.makedirs(output_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(img_path):\n",
      "\u001b[31mNameError\u001b[39m: name 'FINAL_THRESHOLD_JUPYTER' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "MODEL_PATH = '/home/messyas/ml/jetson/runs/detect/yolov8xtrain/weights/best.pt'\n",
    "MODEL_CONF_THR = 0.05\n",
    "IMAGE_TO_PROCESS = \"/home/messyas/Downloads/imagnesTestReais/imagemdeigarapeaerea.jpeg\"\n",
    "OUTPUT_DIR_JUPYTER = \"single_image_output_yolo_jupyter\" \n",
    "\n",
    "def build_yolo_model(model_path: str) -> YOLO:\n",
    "    \"\"\"Carrega o modelo YOLO.\"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"ERRO: Arquivo de pesos YOLO não encontrado: {model_path}\")\n",
    "        return None\n",
    "    try:\n",
    "        model = YOLO(model_path)\n",
    "        print(f\"Modelo YOLO carregado de: {model_path}\")\n",
    "        print(f\"Classes do modelo: {model.names}\")\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao carregar modelo YOLO: {e}\")\n",
    "        return None\n",
    "\n",
    "def predict_yolo(model: YOLO, img_path, conf_threshold):\n",
    "    \"\"\"Executa a predição com o modelo YOLO em CPU e retorna coordenadas em pixels.\"\"\"\n",
    "    results = model.predict(source=img_path, conf=conf_threshold, device='cpu', verbose=False)\n",
    "    result = results[0]\n",
    "    boxes = result.boxes.xyxy.cpu().numpy().tolist()\n",
    "    scores = result.boxes.conf.cpu().numpy().tolist()\n",
    "    labels = result.boxes.cls.cpu().numpy().tolist()\n",
    "    return boxes, scores, labels\n",
    "\n",
    "def draw_enhanced_boxes(img_rgb, filename, predictions, yolo_names, output_dir):\n",
    "    \"\"\"Desenha caixas delimitadoras aprimoradas (AZUIS) sobre fundo P&B e salva.\"\"\"\n",
    "    img_draw = img_rgb.copy()\n",
    "    img_gray = cv2.cvtColor(img_draw, cv2.COLOR_RGB2GRAY)\n",
    "    img_draw = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2RGB)\n",
    "    img_bgr = cv2.cvtColor(img_draw, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    box_color_blue = (255, 100, 0)\n",
    "    text_color = (255, 255, 255)\n",
    "    text_bg_color = (0, 0, 0)\n",
    "    thickness = 4\n",
    "    font_scale = 0.8\n",
    "    font_thickness = 2\n",
    "\n",
    "    for (x1, y1, x2, y2), category_id, score_percentage in predictions:\n",
    "        cat_name = yolo_names.get(category_id, f'ID {category_id}')\n",
    "        label = f\"{cat_name}: {score_percentage}\"\n",
    "        current_box_color = box_color_blue\n",
    "\n",
    "        cv2.rectangle(img_bgr, (x1, y1), (x2, y2), current_box_color, thickness)\n",
    "        (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)\n",
    "        text_y_base = y1 - 10\n",
    "        if text_y_base - text_height - 10 < 0:\n",
    "            text_y_base = y2 + text_height + 15\n",
    "        cv2.rectangle(img_bgr, (x1, text_y_base - text_height - 5), (x1 + text_width, text_y_base + 5), text_bg_color, cv2.FILLED)\n",
    "        cv2.putText(img_bgr, label, (x1, text_y_base), cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, font_thickness, cv2.LINE_AA)\n",
    "\n",
    "    output_filename = f\"pred_yolo_{os.path.basename(filename)}\"\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    cv2.imwrite(output_path, img_bgr)\n",
    "    print(f\"Imagem processada salva em: {output_path}\")\n",
    "\n",
    "def run_prediction_for_jupyter():\n",
    "    \"\"\"Função principal adaptada para rodar no Jupyter.\"\"\"\n",
    "    img_path = IMAGE_TO_PROCESS\n",
    "    output_dir = OUTPUT_DIR_JUPYTER\n",
    "    final_score_threshold = FINAL_THRESHOLD_JUPYTER\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"ERRO: Imagem de entrada não encontrada: {img_path}\")\n",
    "        return\n",
    "\n",
    "    print(\"Carregando modelo YOLOv8...\")\n",
    "    model = build_yolo_model(MODEL_PATH)\n",
    "\n",
    "    if model is None:\n",
    "        print(\"Erro ao carregar o modelo. Abortando.\")\n",
    "        return\n",
    "\n",
    "    yolo_names = model.names\n",
    "\n",
    "    print(f\"Processando imagem: {img_path}\")\n",
    "    img_bgr = cv2.imread(img_path)\n",
    "    if img_bgr is None:\n",
    "        print(f\"ERRO: Não foi possível ler a imagem {img_path}.\")\n",
    "        return\n",
    "\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    print(\"Executando predição...\")\n",
    "    boxes, scores, labels = predict_yolo(model, img_path, MODEL_CONF_THR)\n",
    "\n",
    "    print(f\"Filtrando resultados (limiar = {final_score_threshold*100:.0f}%)...\")\n",
    "    image_predictions_for_plot = []\n",
    "    for b, s, l in zip(boxes, scores, labels):\n",
    "        if s >= final_score_threshold:\n",
    "            x1, y1, x2, y2 = map(int, b)\n",
    "            category_id = int(l)\n",
    "            score_percentage = f\"{s:.1%}\"\n",
    "            image_predictions_for_plot.append(((x1, y1, x2, y2), category_id, score_percentage))\n",
    "\n",
    "    if not image_predictions_for_plot:\n",
    "        print(\"Nenhuma detecção encontrada acima do limiar.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Desenhando {len(image_predictions_for_plot)} caixas delimitadoras...\")\n",
    "    draw_enhanced_boxes(img_rgb, img_path, image_predictions_for_plot, yolo_names, output_dir)\n",
    "\n",
    "    print(\"Processo concluído.\")\n",
    "\n",
    "run_prediction_for_jupyter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d97c99-cd84-4548-831e-12d4097342d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (detectron)",
   "language": "python",
   "name": "detectron"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
